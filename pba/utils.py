"""Utils for parsing PBA augmentation schedules."""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import ast
import collections
import tensorflow as tf
import json

import pba.augmentation_transforms_hp as augmentation_transforms_pba

PbtUpdate = collections.namedtuple('PbtUpdate', [
    'target_trial_name', 'clone_trial_name', 'target_trial_epochs',
    'clone_trial_epochs', 'old_config', 'new_config'
])


def parse_policy(policy_emb, augmentation_transforms):
    policy = []
    num_xform = augmentation_transforms.NUM_HP_TRANSFORM
    xform_names = augmentation_transforms.HP_TRANSFORM_NAMES
    assert len(policy_emb
               ) == 2 * num_xform, 'policy was: {}, supposed to be: {}'.format(
        len(policy_emb), 2 * num_xform)
    for i, xform in enumerate(xform_names):
        # name, prob, magnitude.
        policy.append((xform, policy_emb[2 * i] / 10., policy_emb[2 * i + 1]))
    return policy


def parse_log(file_path, epochs):
    """Parses augmentation policy schedule from log file.

  Args:
    file_path: Path to policy generated by running search.py.
    epochs: The number of epochs search was run for.

  Returns:
    A list containing the parsed policy of the form: [start epoch, start_epoch_clone, policy],
     where each element is a tuple of (num_epochs, policy list).
  """
    raw_policy_file = open(file_path, "r").readlines()
    raw_policy = []
    for line in raw_policy_file:
        try:
            raw_policy_line = json.loads(line)
        except:
            raw_policy_line = ast.literal_eval(line)
        raw_policy.append(raw_policy_line)

    # Depreciated use case has policy as list instead of dict config.
    for r in raw_policy:
        for i in [4, 5]:
            if isinstance(r[i], list):
                r[i] = {"hp_policy": r[i]}
    raw_policy = [PbtUpdate(*r) for r in raw_policy]
    policy = []

    # Sometimes files have extra lines in the beginning.
    to_truncate = None
    for i in range(len(raw_policy) - 1):
        if raw_policy[i][0] != raw_policy[i + 1][1]:
            to_truncate = i
    if to_truncate is not None:
        raw_policy = raw_policy[to_truncate + 1:]

    # Initial policy for trial_to_clone_epochs.
    policy.append([raw_policy[0][3], raw_policy[0][4]["hp_policy"]])

    current = raw_policy[0][3]
    for i in range(len(raw_policy) - 1):
        # End at next line's trial epoch, start from this clone epoch.
        this_iter = raw_policy[i + 1][3] - raw_policy[i][3]
        assert this_iter >= 0, (i, raw_policy[i + 1][3], raw_policy[i][3])
        assert raw_policy[i][0] == raw_policy[i + 1][1], (i, raw_policy[i][0],
                                                          raw_policy[i + 1][1])
        policy.append([this_iter, raw_policy[i][5]["hp_policy"]])
        current += this_iter

    # Last cloned trial policy is run for (end - clone iter of last logged line)
    policy.append([epochs - raw_policy[-1][3], raw_policy[-1][5]["hp_policy"]])
    current += epochs - raw_policy[-1][3]
    assert epochs == sum([p[0] for p in policy])
    return policy


def parse_log_schedule(file_path, epochs, multiplier=1):
    """Parses policy schedule from log file.

  Args:
    file_path: Path to policy generated by running search.py.
    epochs: The number of epochs search was run for.
    multiplier: Multiplier on number of epochs for each policy in the schedule..

  Returns:
    List of length epochs, where index i contains the policy to use at epoch i.
  """
    policy = parse_log(file_path, epochs)
    schedule = []
    count = 0
    for num_iters, pol in policy:
        tf.logging.debug("iters {} by multiplier {} result: {}".format(
            num_iters, multiplier, num_iters * multiplier))
        for _ in range(int(num_iters * multiplier)):
            schedule.append(pol)
            count += 1
    if int(epochs * multiplier) - count > 0:
        tf.logging.info("len: {}, remaining: {}".format(
            count, epochs * multiplier))
    for _ in range(int(epochs * multiplier) - count):
        schedule.append(policy[-1][1])
    tf.logging.info("final len {}".format(len(schedule)))
    return schedule


def parse_schedule_rm_config(file_path):
    lines = open(file_path, "r").readlines()
    lines = [json.loads(line) for line in lines]
    results = []
    for line in lines:
        new_line = [str(e) for e in line[:2]]
        new_line += line[2:4]
        new_line += [line[4]['hp_policy']]
        new_line += [line[5]['hp_policy']]

        results.append(str(new_line) + '\n')

    with open(file_path.split('.txt')[0] + '_0.txt', 'w') as f:
        for e in results:
            f.write(e)


if __name__ == "__main__":
    import matplotlib.pyplot as plt
    import matplotlib.colors as mcolors

    import numpy as np
    import pandas as pd

    colors = ["#1f77b4", "#aec7e8", "#ff7f0e", "#ffbb78", "#2ca02c", "#98df8a", "#d62728", "#ff9896",
                "#9467bd", "#c5b0d5", "#8c564b", "#c49c94", "#e377c2", "#f7b6d2", "#7f7f7f"]

    raw_policy = parse_log_schedule('results/cifar100_ResNet18_Student_4_1e-05_200_0.001_128_MHGD-RKD-SVD_adam_0.4_KD_search/pbt_policy_5.txt', 200)
    # raw_policy = parse_log_schedule('results/ResNet18_cifar100_Teacher_search/pbt_policy_10.txt', 200)
    policy = []
    split = len(raw_policy[0]) // 2
    for pol in raw_policy:
        cur_pol = parse_policy(pol[:split],
                               augmentation_transforms_pba)
        cur_pol.extend(
            parse_policy(pol[split:],
                         augmentation_transforms_pba))
        policy.append(cur_pol)

    labels = [e[0] for e in policy[0][:15]]

    mags = [[(policy[i][j][2] + policy[i][j+15][2])/2.0 for i in xrange(len(policy))] for j in xrange(len(labels))]
    y_mags = np.vstack(mags)
    data = {labels[i]: [y_mags[i][j] for j in xrange(0, 200, 10)] for i in xrange(len(labels))}

    X_AXIS = [str(i) for i in xrange(0, 200, 10)]
    plt.clf()
    df = pd.DataFrame(data, index=X_AXIS)
    ax = df.plot(kind='bar', stacked=True, figsize=(10, 5.7), width=0.6, colors=colors)
    plt.tick_params(labelsize=15)
    plt.xticks(rotation=45)
    # plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=15)
    handles, labels = ax.get_legend_handles_labels()
    ax.legend(handles[::-1], labels[::-1], loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=15, )

    plt.xlabel("Epoch Number", fontsize=20)
    plt.ylabel("Magnitude", fontsize=20)
    # plt.savefig('results/ResNet18_cifar100_teacher_magnitude.jpg', bbox_inches="tight")
    plt.savefig('results/ResNet18_cifar100_student_4_magnitude.jpg', bbox_inches="tight")
    plt.show()

    probs = [[(policy[i][j][1] + policy[i][j+15][1])/2.0 for i in xrange(len(policy))] for j in xrange(len(labels))]
    data1 = {labels[i]: [probs[i][j] for j in xrange(200)] for i in xrange(len(labels))}
    x = xrange(1, 201)
    y_probs = np.vstack([data1[key] for key in sorted(data1.keys())])
    print(labels)
    print(np.max(y_probs))
    plt.figure(figsize=(10, 6))
    division = np.sum(y_probs, axis=0)
    idx = division == 0
    division[idx] = 1
    y_probs = y_probs/max(division)

    plt.stackplot(x, y_probs, labels=sorted(data1.keys()), colors=colors)
    ax = plt.gca()
    handles, labels = ax.get_legend_handles_labels()
    ax.legend(handles[::-1], labels[::-1], loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=15, )
    # plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), fontsize=15, )

    plt.xlim(1.0, 200.0)
    plt.ylim(0, 1.0)
    plt.tick_params(labelsize=15)
    # plt.legend(loc='upper left', fontsize=14)
    plt.xlabel("Epoch Number", fontsize=20)
    plt.ylabel("Probability", fontsize=20)
    # plt.savefig('results/ResNet18_cifar100_teacher_prob.jpg', bbox_inches="tight")
    plt.savefig('results/ResNet18_cifar100_student_4_prob.jpg', bbox_inches="tight")
    plt.show()

